# make sure to mount these dirs into the container (see docker-compose.yml)
DATA_BASE_DIR=./data
MODEL_BASE_DIR=./model



# S3 location and credentials to get the input (staged asset)
INPUT_S3_ENDPOINT_URL=https://some_url
INPUT_ACCESS_KEY_ID=your-key-id
INPUT_SECRET_ACCESS_KEY=your-secret-access-key

# S3 location and credentials to store the output (transcript and provenance)
OUTPUT_S3_ENDPOINT_URL=https://some_url
OUTPUT_ACCESS_KEY_ID=your-key-id
OUTPUT_SECRET_ACCESS_KEY=your-secret-access-key

# S3 location and credentials to obtain the model (optional, see README for model options)
# Remove these lines if you're using a different model option
MODEL_S3_ENDPOINT_URL=https://some_url
MODEL_ACCESS_KEY_ID=your-key-id
MODEL_SECRET_ACCESS_KEY=your-secret-access-key


# Whisper related settings
W_WORD_TIMESTAMPS=y  # or n
W_DEVICE=cuda  # "cpu" to run on CPU, otherwise "cuda" to run on GPU
W_VAD=y  # whether to use voice activity detection (VAD) or not
W_MODEL=large-v2  # check the README for available options
W_BEAM_SIZE=5
W_BEST_OF=5
W_BATCH_SIZE=55

WHISPER_JSON_FILE=whisper-transcript.json
DAAN_JSON_FILE=daan-es-transcript.json
PROVENANCE_FILENAME=provenance.json